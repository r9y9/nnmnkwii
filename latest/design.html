

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>General design documentation &mdash; nnmnkwii 0.0.3.dev0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="nnmnkwii 0.0.3.dev0 documentation" href="index.html"/>
        <link rel="next" title="設計ドキュメント (Japanese)" href="design_jp.html"/>
        <link rel="prev" title="nnmnkwii (nanami) documentation" href="index.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html">
          

          
            
            <img src="_static/logo.png" class="logo" />
          
          </a>

          
            
            
              <div class="version">
                0.0.3.dev0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">General design documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#the-underlying-design-philosophy">The underlying design philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="#background">Background</a></li>
<li class="toctree-l2"><a class="reference internal" href="#goal">Goal</a></li>
<li class="toctree-l2"><a class="reference internal" href="#so-what-do-we-provide">So what do we provide?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#design-decisions">Design decisions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#development-guidelines">Development guidelines</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="design_jp.html">設計ドキュメント (Japanese)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="design_jp.html#the-underlying-design-philosophy">The underlying design philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="design_jp.html#background">Background</a></li>
<li class="toctree-l2"><a class="reference internal" href="design_jp.html#goal">Goal</a></li>
<li class="toctree-l2"><a class="reference internal" href="design_jp.html#so-what-do-we-provide">So what do we provide?</a></li>
<li class="toctree-l2"><a class="reference internal" href="design_jp.html#design-decisions">Design decisions</a></li>
<li class="toctree-l2"><a class="reference internal" href="design_jp.html#development-guidelines">Development guidelines</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nnmnkwii_gallery/notebooks/00-Quick start guide.html">A quick start guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nnmnkwii_gallery/notebooks/00-Quick start guide.html#Playing-with-audio-and-it's-alignment-file">Playing with audio and it’s alignment file</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/00-Quick start guide.html#Load-wav-file">Load wav file</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/00-Quick start guide.html#Acoustic-features">Acoustic features</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/00-Quick start guide.html#Load-aligment-file">Load aligment file</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/00-Quick start guide.html#Cut-silence-frames">Cut silence frames</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/00-Quick start guide.html#Linguistic-features">Linguistic features</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nnmnkwii_gallery/notebooks/00-Quick start guide.html#Playing-with-datasets">Playing with datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/00-Quick start guide.html#Get-example-file-sources">Get example file sources</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/00-Quick start guide.html#Load-data">Load data</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/00-Quick start guide.html#Utterance-wise-iteration">Utterance-wise iteration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nnmnkwii_gallery/notebooks/00-Quick start guide.html#Memory-cache-iteration">Memory cache iteration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/00-Quick start guide.html#Frame-wise-iteration">Frame-wise iteration</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/01-DNN-based statistical speech synthesis (en).html">DNN text-to-speech synthesis (en)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/01-DNN-based statistical speech synthesis (en).html#Data">Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/01-DNN-based statistical speech synthesis (en).html#Data-specification">Data specification</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/01-DNN-based statistical speech synthesis (en).html#File-data-sources">File data sources</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/01-DNN-based statistical speech synthesis (en).html#Utterance-lengths">Utterance lengths</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/01-DNN-based statistical speech synthesis (en).html#How-data-look-like?">How data look like?</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/01-DNN-based statistical speech synthesis (en).html#Statistics">Statistics</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/01-DNN-based statistical speech synthesis (en).html#Combine-datasets-and-normalization.">Combine datasets and normalization.</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/01-DNN-based statistical speech synthesis (en).html#Model">Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/01-DNN-based statistical speech synthesis (en).html#Train">Train</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/01-DNN-based statistical speech synthesis (en).html#Configurations">Configurations</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/01-DNN-based statistical speech synthesis (en).html#Training-loop">Training loop</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/01-DNN-based statistical speech synthesis (en).html#Define-models">Define models</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/01-DNN-based statistical speech synthesis (en).html#Training-Duration-model">Training Duration model</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/01-DNN-based statistical speech synthesis (en).html#Training-acoustic-model">Training acoustic model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/01-DNN-based statistical speech synthesis (en).html#Test">Test</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/01-DNN-based statistical speech synthesis (en).html#Parameter-generation-utilities">Parameter generation utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/01-DNN-based statistical speech synthesis (en).html#Listen-generated-audio">Listen generated audio</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM based RNNs for speech synthesis (en).html">Bidirectional-LSTM based RNNs for text-to-speech synthesis (en)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM based RNNs for speech synthesis (en).html#Data">Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM based RNNs for speech synthesis (en).html#Data-specification">Data specification</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM based RNNs for speech synthesis (en).html#File-data-sources">File data sources</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM based RNNs for speech synthesis (en).html#Utterance-lengths">Utterance lengths</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM based RNNs for speech synthesis (en).html#How-data-look-like?">How data look like?</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM based RNNs for speech synthesis (en).html#Statistics">Statistics</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM based RNNs for speech synthesis (en).html#Combine-datasets-and-normalization.">Combine datasets and normalization.</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM based RNNs for speech synthesis (en).html#Model">Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM based RNNs for speech synthesis (en).html#Train">Train</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM based RNNs for speech synthesis (en).html#Configurations">Configurations</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM based RNNs for speech synthesis (en).html#Trainining-loop">Trainining loop</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM based RNNs for speech synthesis (en).html#Define-models">Define models</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM based RNNs for speech synthesis (en).html#Training-Duration-model">Training Duration model</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM based RNNs for speech synthesis (en).html#Training-acoustic-model">Training acoustic model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM based RNNs for speech synthesis (en).html#Test">Test</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM based RNNs for speech synthesis (en).html#Parameter-generation-utilities">Parameter generation utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM based RNNs for speech synthesis (en).html#Listen-generated-audio">Listen generated audio</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nnmnkwii_gallery/notebooks/vc/01-GMM voice conversion (en).html">GMM-based voice conversion (en)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nnmnkwii_gallery/notebooks/vc/01-GMM voice conversion (en).html#Data">Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/vc/01-GMM voice conversion (en).html#Data-specification">Data specification</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/vc/01-GMM voice conversion (en).html#File-data-sources">File data sources</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/vc/01-GMM voice conversion (en).html#Convert-dataset-to-arrays">Convert dataset to arrays</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/vc/01-GMM voice conversion (en).html#How-data-look-like?">How data look like?</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/vc/01-GMM voice conversion (en).html#Align-source-and-target-features">Align source and target features</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/vc/01-GMM voice conversion (en).html#How-parallel-data-look-like?">How parallel data look like?</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/vc/01-GMM voice conversion (en).html#Append-delta-features">Append delta features</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/vc/01-GMM voice conversion (en).html#Finally,-we-get-joint-feature-matrix">Finally, we get joint feature matrix</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nnmnkwii_gallery/notebooks/vc/01-GMM voice conversion (en).html#Model">Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/vc/01-GMM voice conversion (en).html#Visualize-model">Visualize model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nnmnkwii_gallery/notebooks/vc/01-GMM voice conversion (en).html#Means">Means</a></li>
<li class="toctree-l4"><a class="reference internal" href="nnmnkwii_gallery/notebooks/vc/01-GMM voice conversion (en).html#Covariances">Covariances</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nnmnkwii_gallery/notebooks/vc/01-GMM voice conversion (en).html#Test">Test</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/vc/01-GMM voice conversion (en).html#Listen-results">Listen results</a></li>
<li class="toctree-l3"><a class="reference internal" href="nnmnkwii_gallery/notebooks/vc/01-GMM voice conversion (en).html#How-different?">How different?</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Package references</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="references/autograd.html">Autograd</a><ul>
<li class="toctree-l2"><a class="reference internal" href="references/autograd.html#functional-interface">Functional interface</a><ul>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.autograd.mlpg.html">nnmnkwii.autograd.mlpg</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.autograd.unit_variance_mlpg.html">nnmnkwii.autograd.unit_variance_mlpg</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.autograd.modspec.html">nnmnkwii.autograd.modspec</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="references/autograd.html#function-classes">Function classes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="references/baseline.html">Baseline</a><ul>
<li class="toctree-l2"><a class="reference internal" href="references/baseline.html#module-nnmnkwii.baseline.gmm">GMM voice conversion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="references/datasets.html">Datasets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="references/datasets.html#interface">Interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="references/datasets.html#implementation">Implementation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="references/datasets.html#dataset-that-supports-utterance-wise-iteration">Dataset that supports utterance-wise iteration</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/datasets.html#dataset-that-supports-frame-wise-iteration">Dataset that supports frame-wise iteration</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="references/display.html">Display</a><ul class="simple">
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="references/frontend.html">Frontend</a><ul>
<li class="toctree-l2"><a class="reference internal" href="references/frontend.html#merlin-frontend">Merlin frontend</a><ul>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.frontend.merlin.linguistic_features.html">nnmnkwii.frontend.merlin.linguistic_features</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.frontend.merlin.duration_features.html">nnmnkwii.frontend.merlin.duration_features</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="references/functions.html">Functions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="references/functions.html#mlpg">MLPG</a><ul>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.functions.build_win_mats.html">nnmnkwii.functions.build_win_mats</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.functions.mlpg.html">nnmnkwii.functions.mlpg</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.functions.mlpg_grad.html">nnmnkwii.functions.mlpg_grad</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.functions.unit_variance_mlpg_matrix.html">nnmnkwii.functions.unit_variance_mlpg_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.functions.reshape_means.html">nnmnkwii.functions.reshape_means</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="references/functions.html#modulation-spectrum">Modulation spectrum</a><ul>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.functions.modspec.html">nnmnkwii.functions.modspec</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.functions.modphase.html">nnmnkwii.functions.modphase</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="references/io.html">IO</a><ul>
<li class="toctree-l2"><a class="reference internal" href="references/io.html#module-nnmnkwii.io.hts">HTS IO</a><ul>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.io.hts.load.html">nnmnkwii.io.hts.load</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.io.hts.load_question_set.html">nnmnkwii.io.hts.load_question_set</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="references/metrics.html">Evaluation metrics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="references/generated/nnmnkwii.metrics.melcd.html">nnmnkwii.metrics.melcd</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="references/postfilters.html">Post-filters</a><ul>
<li class="toctree-l2"><a class="reference internal" href="references/generated/nnmnkwii.postfilters.merlin_post_filter.html">nnmnkwii.postfilters.merlin_post_filter</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="references/preprocessing.html">Pre-processing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="references/preprocessing.html#module-nnmnkwii.preprocessing.alignment">Alignment</a></li>
<li class="toctree-l2"><a class="reference internal" href="references/preprocessing.html#module-nnmnkwii.preprocessing.f0">F0</a><ul>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.preprocessing.f0.interp1d.html">nnmnkwii.preprocessing.f0.interp1d</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="references/util.html">Utilities</a><ul>
<li class="toctree-l2"><a class="reference internal" href="references/util.html#utterance-wise-operations">Utterance-wise operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.util.delta.html">nnmnkwii.util.delta</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.util.apply_delta_windows.html">nnmnkwii.util.apply_delta_windows</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.util.trim_zeros_frames.html">nnmnkwii.util.trim_zeros_frames</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.util.remove_zeros_frames.html">nnmnkwii.util.remove_zeros_frames</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.util.adjast_frame_length.html">nnmnkwii.util.adjast_frame_length</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.util.scale.html">nnmnkwii.util.scale</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.util.minmax_scale.html">nnmnkwii.util.minmax_scale</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="references/util.html#dataset-wise-operations">Dataset-wise operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.util.meanvar.html">nnmnkwii.util.meanvar</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.util.meanstd.html">nnmnkwii.util.meanstd</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.util.minmax.html">nnmnkwii.util.minmax</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="references/util.html#files">Files</a><ul>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.util.example_label_file.html">nnmnkwii.util.example_label_file</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.util.example_audio_file.html">nnmnkwii.util.example_audio_file</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.util.example_question_file.html">nnmnkwii.util.example_question_file</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.util.example_file_data_sources_for_duration_model.html">nnmnkwii.util.example_file_data_sources_for_duration_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.util.example_file_data_sources_for_acoustic_model.html">nnmnkwii.util.example_file_data_sources_for_acoustic_model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="references/util.html#module-nnmnkwii.util.linalg">Linear algebra</a><ul>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.util.linalg.cholesky_inv.html">nnmnkwii.util.linalg.cholesky_inv</a></li>
<li class="toctree-l3"><a class="reference internal" href="references/generated/nnmnkwii.util.linalg.cholesky_inv_banded.html">nnmnkwii.util.linalg.cholesky_inv_banded</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">nnmnkwii</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>General design documentation</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/design.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

/* nice headers on first paragraph of info/warning boxes */
.admonition .first {
    margin: -12px;
    padding: 6px 12px;
    margin-bottom: 12px;
    color: #fff;
    line-height: 1;
    display: block;
}
.admonition.warning .first {
    background: #f0b37e;
}
.admonition.note .first {
    background: #6ab0de;
}
.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}
</style>
<div class="section" id="general-design-documentation">
<h1>General design documentation<a class="headerlink" href="#general-design-documentation" title="Permalink to this headline">¶</a></h1>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Design issue tracker <a class="reference external" href="https://github.com/r9y9/nnmnkwii/issues/8">https://github.com/r9y9/nnmnkwii/issues/8</a></p>
</div>
<div class="section" id="the-underlying-design-philosophy">
<h2>The underlying design philosophy<a class="headerlink" href="#the-underlying-design-philosophy" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Getting better experience on rich REPL (i.e, IPython, Jupyter) boosts research productivity.</li>
</ul>
</div>
<div class="section" id="background">
<h2>Background<a class="headerlink" href="#background" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Statistical speech synthesis system typically involves many area of research; roughly speaking, text processsing, speech analysis / synthesis and machine learning, etc. Sometimes it’s hard to prototype new ideas since it usually requires many deep knowledge among these areas. I think it’s worth to create common reusable software for ease of future research.</li>
<li>In HMM speech synthesis, <a class="reference external" href="http://hts.sp.nitech.ac.jp/">HTS</a> have been widely used. They provide various command line tools to allow users to create their own HMM-based statistical speech synthesis systems. However, it doesn’t meet the requirements nowadays, since it’s been known that DNN-based speech synthesis system can outperform HMM-based ones.</li>
<li><a class="reference external" href="https://github.com/CSTR-Edinburgh/merlin">Merlin</a>, which is an open source DNN-based speech synthesis toolkit, is a successor of HTS. Merlin was created to satisfy needs for DNN-based speech synthesis. One of their purpose is to help research reproducibility. From their reports, lots of research uses the toolkit to do research. That’s great. However, from my perspective, it lacks flexibility. From their design, the main entry point for users is run_merlin.py, which does <em>everything</em> for you. We use Merlin to provide configuration file to the run_merlin.py. The problem of the design is that we cannot simply reuse Merlin’s part of functionality other than through the run_merlin.py. Similarly, Merlin is built on top of Theano and keras as their computational backends, we cannot simply use other computational backends (PyTorch, tensorflow, etc) with Merlin.</li>
</ul>
<p>From the background described above, I think I need a new flexible and modular library. This is why I started to create the library.</p>
</div>
<div class="section" id="goal">
<h2>Goal<a class="headerlink" href="#goal" title="Permalink to this headline">¶</a></h2>
<p>In my philosophy, I believe getting better experience on rich REPL (IPython, Jupyter) boosts research productivity. From this in mind, my goal is to create a modular and reusable library focused on</p>
<ul class="simple">
<li>Easy and fast prototyping</li>
</ul>
<p>The libray is MIT-licensed. I hope this will help you.</p>
</div>
<div class="section" id="so-what-do-we-provide">
<h2>So what do we provide?<a class="headerlink" href="#so-what-do-we-provide" title="Permalink to this headline">¶</a></h2>
<p>Please correct me if I’m saying wrong things about speech synthesis. Recently there’s been many progress on speech synthesis research. Besides the success of typical DNN-based speech synthesis, end-to-end speech synthesis (e.g., <a class="reference external" href="http://www.josesotelo.com/speechsynthesis/">Char2Wav</a>), vocoder-less speech synthesis (e.g., <a class="reference external" href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/">WaveNet</a>) have been investigated. To design software, we cannot practically cover all the techniques. If we want to do this, I think it complicates the software overly. In my option, it’s important to focus on generic algorithms, that can be used as building blocks.</p>
<p>From the success of deep learning, many computational backends (e.g., tensorflow, PyTorch, etc) have been created to help research.
I think we should provide a library which bridges generic computational backends and speech data. Hence, in this library, we provide</p>
<ul class="simple">
<li>Dataset and data iteration abstractions, considering arbitrary large datasets. <a class="reference internal" href="references/datasets.html#module-nnmnkwii.datasets" title="nnmnkwii.datasets"><code class="xref py py-obj docutils literal"><span class="pre">nnmnkwii.datasets</span></code></a></li>
<li>Generic functions for speech synthesis. <a class="reference internal" href="references/autograd.html#module-nnmnkwii.autograd" title="nnmnkwii.autograd"><code class="xref py py-obj docutils literal"><span class="pre">nnmnkwii.autograd</span></code></a>, <a class="reference internal" href="references/functions.html#module-nnmnkwii.functions" title="nnmnkwii.functions"><code class="xref py py-obj docutils literal"><span class="pre">nnmnkwii.functions</span></code></a></li>
<li>Pre-processsing, post-processsing and utilities. <a class="reference internal" href="references/preprocessing.html#module-nnmnkwii.preprocessing" title="nnmnkwii.preprocessing"><code class="xref py py-obj docutils literal"><span class="pre">nnmnkwii.preprocessing</span></code></a>, <a class="reference internal" href="references/util.html#module-nnmnkwii.util" title="nnmnkwii.util"><code class="xref py py-obj docutils literal"><span class="pre">nnmnkwii.util</span></code></a>, <a class="reference internal" href="references/postfilters.html#module-nnmnkwii.postfilters" title="nnmnkwii.postfilters"><code class="xref py py-obj docutils literal"><span class="pre">nnmnkwii.postfilters</span></code></a></li>
</ul>
<p>As I believe visualization is important to understand what happens, I plan to provide visualization package (<a class="reference internal" href="references/display.html#module-nnmnkwii.display" title="nnmnkwii.display"><code class="xref py py-obj docutils literal"><span class="pre">nnmnkwii.display</span></code></a>) in the near future.</p>
</div>
<div class="section" id="design-decisions">
<h2>Design decisions<a class="headerlink" href="#design-decisions" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li>We provide our library as python packages that can be used in REPL. Command line tools, which would be useful for batch processing, are not included. Users are expected to create their own command line tools if necessary.</li>
<li>We use in-memory IO as possible, except for loading dataset from files.</li>
<li>We don’t provide duration/acoustic models, opposite to Merlin. Users are expected to implement their own ones. For generic models may go in <code class="xref py py-obj docutils literal"><span class="pre">nnmnkwii.baseline</span></code> module, but it’s not meant to cover all the models.</li>
<li>We don’t provide linguistic feature extraction frontend, except for utilities to convert structural linguistic information (e.g., HTS full-context labels ) to its numeric forms.</li>
<li>We don’t provide speech analysis/synthesis backend. Users are expected to use another packages for this purpose. e.g., <a class="reference external" href="https://pysptk.readthedocs.io/en/latest/index.html#module-pysptk" title="(in pysptk v0.1.8.dev0)"><code class="xref py py-obj docutils literal"><span class="pre">pysptk</span></code></a>, <code class="xref py py-obj docutils literal"><span class="pre">pyworld</span></code> and <code class="xref py py-obj docutils literal"><span class="pre">librosa</span></code>.</li>
</ol>
<p>We will try to keep the library to be modular, easy to understand and reusable.</p>
</div>
<div class="section" id="development-guidelines">
<h2>Development guidelines<a class="headerlink" href="#development-guidelines" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><strong>Do not reinvent the wheel</strong>: Avoid reinventing the wheel as possible.</li>
<li><strong>Fully unit tested</strong>: There’s no software that has no bugs.</li>
<li><strong>Documentation</strong>: Well documented software will help users to get stared.</li>
</ul>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="design_jp.html" class="btn btn-neutral float-right" title="設計ドキュメント (Japanese)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="nnmnkwii (nanami) documentation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Ryuichi Yamamoto.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.0.3.dev0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>