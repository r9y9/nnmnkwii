General design documentation
============================

The underlying design principle
-------------------------------

-  対話環境 (e.g., IPython, Jupyter)
   での試行錯誤は、生産性の向上に重要である

TODO: Think carefully
---------------------

-  lanugage-dependent frontendはどうする？
-  end-to-end系の扱いはどうする？今後の主流になっていくと思われる

Background
----------

-  統計的音声合成（以下、音声合成）、統計的声質変換（以下、声質変換）は、多くの要素技術からなる技術であり、論文の追試（結果の再現）、新しいアイデアをプロトタイピングするといった行為は、大きな労力を要する
-  HMM音声合成では、HTSが広く使われている。HTKにパッチを適用することで使用する。HMMベースの音響モデルを構築するための仕組みがコマンドラインツール群として提供されており、それらを組みわせて柔軟にシステムが作れるように設計されている。しかし、HMMベースの音声合成に着目して設計されているため、DNN音声合成には基本的には対応していない。 [1]_
   また、HTSを用いたHMM合成システム全体は単純ではなく（例えば、デモスクリプト内の学習スクリプト
   Training.pl
   は、約3000行ある）、そのある構成要素において、いったいどのような処理が行われているのかをコードを読むことで知ることは、専門家でなければ難しい。また、コードを動かしながら、あるパラメータがどのような意味を持つのかを調べることもできるが、学習には数時間以上かかるため、試行錯誤には非常に時間がかかる。
-  `Merin <http://ssw9.net/papers/ssw9_PS2-13_Wu.pdf>`__
   は、DNNベースの音声合成システムを作るためのツールキットである。近年のDNNベースの音声合成システムの成功を受けて、HTSのに代わるDNNベースのstate-of-the-artなシステムを再現可能な形で提供するために作られている。HTSと同様、音響モデリングにフォーカスしている。音声認識のためのライブラリであるkaldiに習い、レシピという形で音声合成を行うためのスクリプト（HTSでのデモスクリプトにあたる）を提供している。Melinの主なエントリーポイントは、run\_merlin.pyというコマンドラインスクリプトであり、ユーザは設定ファイルを切り替えることで、どのような音響モデルを使用するかなどを切り替える。しかし、APIとして設計されているわけではなく、構成要素を一部利用するといったことが難しい。例えば、設定ファイルでは対応不可能な自作の音響モデルを使用したい場合、merlin内部（merlin/src以下）においてどのように音響モデルが使われているか（undocmented）を知る必要があり、内部を熟知している者以外には困難である。

まとめると、音声合成における構成要素を対話的に試すことができ、HMM音声合成だけでなく、DNN音声合成、さらにはEnd-to-end音声合成も視野に入れたソフトウェアがあると望ましいと考える。

Goal
----

対話環境での試行錯誤が研究の生産性の向上に重要であると信じ、対話環境での利用を前提とした、音声合成、声質変換などの音声に特化した機械学習の共通基盤を構築することを目的とする。コードはMITライセンスで公開し、研究の再現性の保証にも役立つことも狙う。

音声合成においては、言語特徴量＋音響特徴量を入力としたDNN音声合成だけでなく、End-to-end音声合成の構成要素としても使用可能であることも目標とする。

So what do we need?
-------------------

HMM音声合成からのDNN音声合成の発展、End-to-end音声合成、Wavenetのようなボコーダレスの音声合成の発展など、音声合成の枠組みは多岐に渡る。すべてを網羅する機能を提供することは困難であり、ライブラリを複雑かつメンテナンスを難しいものにしてしまう。したがって、提供する機能を最も汎用的な部分に留めることが重要であると考える。

DNNを用いた機械学習においては、tensorflow, keras, cntk, pytorch, theano,
caffe2,
chainerに代表されるように、CUDAを活用した多次元配列（テンソル）上の数値演算、自動微分をサポートしたフレームワークが必須になってきている。音声、画像、言語など、データをテンソルとして表現できる場合は多くあり、ドメインを問わず多くの分野で使われている。本ライブラリは、そういった汎用的な自動微分フレームワークと併せて使用されることを想定し、

-  言語特徴量、音響特徴量に対するテンソル表現、データアクセスの抽象化
-  必要最低限の前処理アルゴリズム
-  音声に特化した自動微分をサポートした関数（autograd functions）

に注目し、機能を提供すればよいと考える。また、可視化が重要であるという信念のもと、言語特徴量、音響特徴量の可視化ツールも提供する。

Design decisions
----------------

ソフトウェアの設計方針として、以下が挙げられる。

1. 対話環境で使えるPythonパッケージとして提供する。コマンドラインツールは、必要であればユーザが作ればよいと考え、本ライブラリでは提供しないこととする。
2. 対話環境での使用を前提とするため、基本的にIOはin-memoryととる。ファイルIOをAPIには使用しない
3. 音響モデルの提供は、ライブラリの範囲外とする。もっともユーザが自分で考えて設定したい部分と考えられるためである。音響モデルを提供するのではなく、音響モデルを構築するための要素を提供する。
4. 言語特徴量の抽出 (i.e. frontend)
   は、HTSやMerlinと同様に、ライブラリの範囲外とする。
5. 音響特徴量の抽出は、ライブラリの範囲外とする。 ``pysptk``,
   ``pyworld``, ``librosa``\ など別パッケージを使用すればよい。
6. 速度より可読性重視

HTSのデモスクリプトのように、音声合成システム全体が複雑になってしまうのは、避けられない問題であると考える。本ライブラリでは、構成要素がシンプルで小さく、要素同士が疎結合であることを目指し、理解しやすい、再利用しやすいソフトウェアを目指す。

Development guidelines
----------------------

開発においては、以下を指針とする

-  **Respect other frameworks**: 車輪の再発明は可能な限り避ける
-  **Fully unit tested**:
   バグのないソフトウェアはない。テストによって、可能な限りバグを少なくする、再発を避ける。
-  **Documentation**: ドキュメントを書くのは大変だが、大事である

Summary
-------

WIP: Data abstractions, preprocessing and autograd functions for machine
learning on speech designed for interactive prototyping.

-  **Designed for interactive prototyping**
-  **Modular design**: 疎結合な設計、APIとしての利用前提
-  **Tensor & autograd friendly**:
   最小限の労力で、自動微分フレームワークと併せて使用可能

.. [1]
   DNN音声合成を行うデモスクリプトは存在するが、あくまでデモスクリプトであり、ライブラリとしての機能にあるわけではない。
